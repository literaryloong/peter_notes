FAULTS RECORDS
=================
1. ES 报错 NoNodeAvailableException
	ES集群的IP、端口或集群名称是否正确(es-savoir,not es-savior)
	
2. 本机调试代码报错：org.apache.hadoop.security.AccessControlException: Permission denied: user=yww08, access=WRITE, inode="/anxinyun/structure_data/structure_2/raw/2018/7/液位变送器1.csv":testerone:supergroup:-rw-r--r--
	设置环境变量
	System.setProperty("HADOOP_USER_NAME",hdfsUser)
	
3. 已拥有为“NETStandard.Library”定义的依赖项。
	工具栏---工具----扩展和更新 重装nuget升级
	
4.  Spark: URI is not hierarchical
	引用资源文件错误，修改 `val source=Source.fromFile(getClass.getResource("/jiangsu.json").toURI)`  >> `val source=Source.fromInputStream(getClass.getResourceAsStream("/jiangsu.json"))`
	
5. [Savoir]  修改在Rdd.foreachPartition中存储后，出现Hdfs存储错误：
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /savoir/structure_data/structure_4/theme/2018/7/温湿度.csv for DFSClient_NONMAPREDUCE_-602640997_1250 on 10.8.30.117 because DFSClient_NONMAPREDUCE_-602640997_1250 is already the current lease holder.
	排查可能存在多线程读写文件：
	
6：No configuration setting found for key 'akka'
	<https://stackoverflow.com/questions/31011243/no-configuration-setting-found-for-key-akka-version>
	使用插件maven-shade-plugin,配置见具体项目；
	其中： 
	```xml
		<filters>
			<filter>
				<!--错误:Invalid signature file digest for Manifest main attributes-->
				<artifact>*:*</artifact>
				<excludes>
					<exclude>META-INF/*.SF</exclude>
					<exclude>META-INF/*.DSA</exclude>
					<exclude>META-INF/*.RSA</exclude>
				</excludes>
			</filter>
		</filters>
	```
	
7. java.util.concurrent.TimeoutException: Futures timed out after [100000 milliseconds]
	配置profile未修改为production发布，即还是使用new SparkConf().setMaster("local[*]").setAppName(appname)初始化SparkConf
	
8. Offset commit failed.
	org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
	简单翻译一下，“位移提交失败，原因是消费者组开启了rebalance且已然分配对应分区给其他消费者。这表明poll调用间隔超过了max.poll.interval.ms的值，这通常表示poll循环中的消息处理花费了太长的时间。解决方案有两个：1. 增加session.timeout.ms值；2. 减少max.poll.records值”
	
	1. group.max.session.timeout.ms in the server.properties > session.timeout.ms in the consumer.properties.
	2. group.min.session.timeout.ms in the server.properties < session.timeout.ms in the consumer.properties.
	3. request.timeout.ms > session.timeout.ms and fetch.max.wait.ms
	4. (session.timeout.ms)/3 > heartbeat.interval.ms
	5. session.timeout.ms > Worst case processing time of Consumer Records per consumer poll(ms).
	
9. IntelliJ IDEA中提交svn时卡在 performing vcs refresh
	File > Invalidate Caches / Restart...   选择 Invalidate and Restart

10. kubeadm join token过期
	$ kubeadm token create
	abcdef.1234567890abcdef

	# get root ca cert fingerprint
	$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
	e18105ef24bacebb23d694dad491e8ef1c2ea9ade944e784b1f03a15a0d5ecea 





(运行支持kubernetes原生调度的Spark程序)[https://jimmysong.io/kubernetes-handbook/usecases/running-spark-with-kubernetes-native-scheduler.html]

############ AXY部署：
0. K8S环境部署 [](./kubeadm.html)
	
	重装需要清理环境：+
	```
		rm -rf /var/lib/cni/
		rm -rf /var/lib/kubelet/*
		rm -rf /etc/cni/
		ifconfig cni0 down
		ifconfig flannel.1 down
		ifconfig docker0 down
	```
	root下执行提示cr5什么的，是因为配置文件/root/.kube/xxx.config文件缺失

1. Ambari安装后，kafka执行程序路径：
	/usr/hdp/current/kafka-broker/bin
	./kafka-console-consumer.sh --bootstrap-server anxinyun-m1:6667,anxinyun-n1:6667,anxinyun-n2:6667 --topic anxinyun_data --from-beginning

	
2. Group coordinator anxinyun-n2:6667 (id: 2147482644 rack: null) is unavailable or invalid, will attempt rediscovery

	问题分析： stackwork提示 容器内hosts无法连接外部kafka broker
	解决：修改 kube-dns
	
	#kubectl get pod kube-dns-545bc4bfd4-qzcrt -n kube-system -o yaml --export -f dns/dns.yaml
	
	kubectl get deploy kube-dns -o yaml -n kube-system > kube-deploy.yaml
	
	添加一下内容：
	```
	dnsPolicy: Default
      hostAliases:
      - hostnames:
        - anxinyun-m1
        ip: 10.8.30.176
      - hostnames:
        - anxinyun-n1
        ip: 10.8.30.177
      - hostnames:
        - anxinyun-n2
        ip: 10.8.30.179
      nodeName: anxinyun-m1
	  ```
	  kubectl delete -f kube-deploy.yaml
	  kubectl create -f kube-deploy.yaml
	
3. [WARN] The short-circuit local reads feature cannot be used because libhadoop cannot be loaded
	同 local hdfs lib not found, 忽略

4. java.lang.ClassNotFoundException: scala.Product  
	运行docker的scala进程时报错
	> kafka 版本错误： 2.12->> 2.11
	
	Exception in thread "main" java.lang.ClassNotFoundException: a=1
	you need to provide exactly one argument: the class of the application supervisor actor
	
	> 修改了pom中的shade-pluging
	
	No configuration setting found for key 'akka.version'
	
	> shade-pluging中增加配置，
		<transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
			<resource>reference.conf</resource>
		</transformer>
		
5.[ERROR] [07/29/2018 05:51:33.289] [default-rediscala.rediscala-client-worker-dispatcher-5] [akka://default/user/RedisClient-$a] CommandFailed(Connect( anxinyun-n1:6379,None,List(KeepAlive(true)),None,false))
	k8s pod的yaml配置文件中，redis.host= anxinyun-n2 中间多了一个空格(MMP)
	
6.  KafkaConsumer is not safe for multi-threaded access

	KafkaConsumer和操作它的线程数必须是1对1的关系
	
7. Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Protocol message end-group tag did not match expected tag.; Host Details : local host is: "spark-et-driver/10.244.1.19"; destination host is: "anxinyun-m1":9000;
	hdfs url配错，ambari默认8020而非9000

7.1  Checkpoint RDD has a different number of partitions from original RDD. Original RDD [ID: 10658, num of partitions: 2]; Checkpoint RDD [ID: 10685, num of partitions: 0].
	
	> 修改cp目录从本地文件格式为 hdfs://.... ....
	又出现 
		org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/user/hdfs/anxinyun-check-point/e7236205-88b8-4d0e-bb3c-12d2549f8ad6/rdd-371/.part-00000-attempt-3":hdfs:hdfs:drwxr-xr-x
			> submit添加如下参数
			--conf spark.kubernetes.driverEnv.SPARK_USER=hdfs \
			--conf spark.kubernetes.driverEnv.HADOOP_USER_NAME=hdfs \
			--conf spark.executorEnv.HADOOP_USER_NAME=hdfs \
			--conf spark.executorEnv.SPARK_USER=hdfs \
			
			还可以通过：
			sudo -u hdfs hdfs dfs -chmod -R 775 /user/check-point
			或者修改hdfs中超级用户组和权限配置：
			fs.permissions.umask-mode=002  dfs.permissions.superusergroup=hdfs   dfs.permissions=false(直接关闭权限验证)
			
			又出现
				Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try
				
				hdfs conf +++
			又出现
				org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to APPEND_FILE /anxinyun/structure_data/structure_1/raw/2018/7/WSD#1.csv for DFSClient_NONMAPREDUCE_50217299_1 on 10.8.30.179 because DFSClient_NONMAPREDUCE_50217299_1 is already the current lease holder.

	[参考]:
		<https://community.hortonworks.com/questions/202369/datanode-failed-to-replace-a-bad-datanode-on-the-e.html>
		<https://community.hortonworks.com/articles/16144/write-or-append-failures-in-very-small-clusters-un.html>

				

8. OOMKilled
	spark driver在k8s中运行一段时间出现 OOMKilled
	未复现
	
9. WEB UI （spark on k8s）
	kubectl port-forward spark-et-driver -n anxinyun  4040:4040
	仅能在driver机器上通过localhost:4040访问
	
	
第二次部署踩坑(08.01)
1. ubuntu系统无法进入
	所有文件处于只读状态
	可以通过 mount -o remount / 方法临时修改，但是重启后依旧
	解决方法：重装系统
	
2. hdb-selecter not found 
	`ambari仓库配置错了`
	'hadoop-client ... failed, ' error param conf
	`/etc/hadoop/conf文件丢失了，重装ambari时会发生的错误，解决方法：手动拷贝`
	kafka-broker启动失败
	``

3. k8s安装完成后所有节点处于NotReady状态
	kubectl get nodes -o wide
	发现kenerl和k8s版本不一致
	解决方法：系统upgrade后，执行以下命令：
		kubeadm reset 
		systemctl stop kubelet
		rm -rf /var/lib/cni/
		rm -rf /var/lib/kubelet/*
		rm -rf /run/flannel
		rm -rf /etc/cni/
		ifconfig cni0 down
		ifconfig flannel.1 down
		ip link delete cni0
		ip link delete flannel.1
		apt purge -y kubelet kubeadm kubectl kubernetes-cni 
		systemctl daemon-reload
		apt install kubernetes-cni=0.5.1-00 kubelet=1.8.2-00 kubeadm=1.8.2-00 kubectl=1.8.2-00
		
		修改配置
		vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 

		添加：
		Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false"
		重启服务
		systemctl daemon-reload
		systemctl restart kubelet
		关闭交互分区

		swapoff -a  

		删除 /etc/fstab 表中的交换分区记录
	
10. 其他错误
	lient Version: version.Info{Major:"1", Minor:"8", GitVersion:"v1.8.2", GitCommit:"bdaeafa71f6c7c04636251031f93464384d54963", GitTreeState:"clean", BuildDate:"2017-10-24T19:48:57Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"linux/amd64"}
	Error from server (NotFound): the server could not find the requested resource
	
	
	vents:
  Type     Reason                 Age                From                  Message
  ----     ------                 ----               ----                  -------
  Normal   Scheduled              11m                default-scheduler     Successfully assigned spark-et-driver to anxinyun-n2
  Normal   SuccessfulMountVolume  11m                kubelet, anxinyun-n2  MountVolume.SetUp succeeded for volume "download-jars-volume"
  Normal   SuccessfulMountVolume  11m                kubelet, anxinyun-n2  MountVolume.SetUp succeeded for volume "download-files-volume"
  Warning  FailedMount            11m                kubelet, anxinyun-n2  MountVolume.SetUp failed for volume "spark-init-properties" : configmaps "spark-et-94a3f73e5af13b2d83fb23ba02973cda-init-config" not found
  Normal   SuccessfulMountVolume  11m                kubelet, anxinyun-n2  MountVolume.SetUp succeeded for volume "anxinyun-token-vh5hj"
  Normal   SuccessfulMountVolume  11m                kubelet, anxinyun-n2  MountVolume.SetUp succeeded for volume "spark-init-properties"
  Normal   Pulling                10m (x3 over 11m)  kubelet, anxinyun-n2  pulling image "registry.zhiwucloud.com/anxinyun/spark:latest"
  Warning  Failed                 10m (x3 over 11m)  kubelet, anxinyun-n2  Failed to pull image "registry.zhiwucloud.com/anxinyun/spark:latest": rpc error: code = Unknown desc = Error response from daemon: manifest for registry.zhiwucloud.com/anxinyun/spark:latest not found
  Warning  FailedSync             10m (x8 over 11m)  kubelet, anxinyun-n2  Error syncing pod
  Normal   BackOff                1m (x43 over 11m)  kubelet, anxinyun-n2  Back-off pulling image "registry.zhiwucloud.com/anxinyun/spark:latest"
  
  
## 测试环境合并
1. kubernetes Network Plugin cni failed
	kubernetes flannel Failed to find any valid interface to use
	节点上的flannel pod一直处于 Init:CrashLoopBackOff
	
	解决方法： 判断节点网络是否有问题(能否访问外网、解析域名)
			重装节点kubenertes(上3)

			
## 代码重构1.0 
IDEA 2017.1.6 et
1. scala project Error:java: Compilation failed: internal java compiler error
	
	设置 > java compiler > 设置jdk版本
	
2. Diamond type are not supported at this language level
	Ctrl+Alt+Shift+S (项目设置 ) > Language Level > 8 - Lambdas,type annotations etc.	
	
3.  HDFS文件的错误：No FileSystem for scheme: hdfshttps://www.codelast.com/%E5%8E%9F%E5%88%9B-%E8%A7%A3%E5%86%B3%E8%AF%BB%E5%86%99hdfs%E6%96%87%E4%BB%B6%E7%9A%84%E9%94%99%E8%AF%AF%EF%BC%9Ano-filesystem-for-scheme-hdfs/

4. Exception in thread "main" java.lang.NoClassDefFoundError: scala/Function1
	添加引用
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>2.11.8</version>
        </dependency>
		

5. java项目resource中文件复制到target/class目录下后内容发生了改变(例如https的cacerts.store文件)
	原因： maven resouce的filter插件
	修改为：
	```xml
        <resources>
            <resource>
                <filtering>true</filtering>
                <directory>../src/main/resources</directory>
            </resource>
            <resource>
                <filtering>true</filtering>
                <directory>${project.basedir}/src/main/resources</directory>
                <includes>
                    <include>*.properties</include>
                </includes>
            </resource>
            <resource>
				<!-- 不使用过滤的资源文件 -->
                <filtering>false</filtering>
                <directory>${project.basedir}/src/main/resources</directory>
                <excludes>
                    <exclude>*.properties</exclude>
                </excludes>
            </resource>
        </resources>
	```

6. et_upload 中创建多个kafkastream时接收不到数据
	??
	
7. postman请求https无响应
	postman设置，关闭 SSL certificate verification
	
以后：
1. Caused by: java.io.IOException: Cannot run program "I:\@\hadoop-2.7.3\bin\winutils.exe": CreateProcess error=5, 拒绝访问。
	在windows机器中安装hadoop，参见[3]

2. Offsets out of range with no configured reset policy for partitions (spark-stream kafka)
	https://www.jianshu.com/p/40aee290f484
	
3. windows上安装hadoop （问题1解决思路）
	https://blog.csdn.net/rav009/article/details/70214788
	> https://mirrors.cnnic.cn/apache/hadoop/common/ 下载hadoop镜像并解压
	> https://github.com/steveloughran/winutils 下载对应winutils 覆盖到bin
	> 设置 HADOOP_HOME 以及 Path
	> 修改etc/hadoop-env.cmd下
	  set JAVA_HOME=C:\PROGRA~1\Java\jdk1.8.0_121
	> core-site:
	 <configuration>
			<property>
					<name>fs.defaultFS</name>
					<value>hdfs://localhost:9000</value>
			</property>
	 </configuration>
	> hdfs-site.xml
		<configuration>
				<property>
						<name>dfs.replication</name>
						<value>1</value>
				</property>
				<property>
						<name>dfs.namenode.name.dir</name>
						<value>file:/hadoop/data/dfs/namenode</value>  相同盘符根目录下响应位置
				</property>
				<property>
						<name>dfs.datanode.data.dir</name>
						<value>file:/hadoop/data/dfs/datanode</value>
				</property>
		</configuration>
	> hadoop namenode -format
	  如果不行就修改数据文件夹的权限(everyone)
	> cd sbin
	> start-dfs.cmd
	> OK

4. could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.
	怀疑存储空间不足，待验证
	
5. Too many dynamic script compilations within one minute (ElasticSearch)
	重启进程
	
6. mqtt receiver进程重复接收数据；
	savoir的receiver进程中仅订阅了savoir_data，确会收到anxinyun_data的数据
	怀疑：client.id之前订阅过anxinyun_data主题
	解决方法： 修改client.id
	
7. [ERROR] Caused by: java.lang.AssertionError: assertion failed: org.joda.convert.ToString
	scala maven项目编译能通过，执行mvn install时提示错误：
	除了引用joda-time库外还需要引用 joda-convert库
	
8. 安心云ET运行一段时间报错：[Executor] Executor self-exiting due to : Driver spark-et-baed51c5f49f33339750c4602718b303-driver-svc.anxinyun.svc:7078 disassociated! Shutting down
	应该是OOM后被kill,   继续排查spark内存泄漏的问题
	参见[https://www.jianshu.com/p/80dc6209acc0]
	
9. Offsets out of range with no configured reset policy for partitions


10. receiver进程 Lost connection. reconnecting...
Client is connected (32100)
	at org.eclipse.paho.client.mqttv3.internal.ExceptionHelper.createMqttException(ExceptionHelper.java:31)
	at org.eclipse.paho.client.mqttv3.MqttAsyncClient.connect(MqttAsyncClient.java:731)
	
	在mqtt断连回调事件中，将connect方法修改为reconnect
	*(继续跟踪是否解决)
	
11. spark monitor:
记录
http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.SparkListener

12. org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2727.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2727.0 (TID 1122, 10.244.1.109, executor 1): java.lang.NoClassDefFoundError: Could not initialize class et.agg.AggConfig$
 在商用环境用K8S部署ET时出错，同样版本在测试环境正常
 因为在AggConfig初始化代码中出现异常，JSON反序列化构造对象后调用redis初始部分属性超时（测试环境没有超时）

13. java.lang.IllegalStateException: Previously tracked partitions [anxinyun_data2-0] been revoked by Kafka because of consumer rebalance. This is mostly due to another stream with same group id joined, please check if there're different streaming application misconfigure to use same group id. Fundamentally different stream should use different group id
	在商用环境同时起2个K8S-ET，出错
	
14. ES启动失败：bootstrap checks failed  max virtual memory areas vm.max_map_count [65530] is too low
	sudo sysctl -w vm.max_map_count=262144 [ref](https://github.com/docker-library/elasticsearch/issues/111)

15. ES脑裂
	https://my.oschina.net/LucasZhu/blog/1543971
	在商用环境重启ES进程(jvm.Xmx设置),导致重启后没有自动组成集群
	ET入库时显示数据插入成功，查询时发现数据丢失
	
16. java内存管理
	BIG ISSUE
	没有设置xmx，默认(java8) 1/6 physical memory ~ 1/4 physical memory
	You can Check the default Java heap size by:
	java -XX:+PrintFlagsFinal -version | grep -iE 'HeapSize|PermSize|ThreadStackSize'
	
	默认GC规则
	Default garbage collectors:
	Java 7 - Parallel GC
	Java 8 - Parallel GC
	Java 9 - G1 GC
	Java 10 - G1 GC
	[gcpic](https://i.stack.imgur.com/XHfx0.jpg)

	【A Templator Handler】：AXY3.0部分java进程加上默认限制：（recalc,et-hdfs,abn,analyse,fc-alarm,aggregation）
	-Xmx2G -Xms2G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps
	
17. KAFKA IN SPARK-STREAMING常见问题：
	1). 提交OFFSET Rebalance的告警
	
	2).xxxx been revoked by Kafka because of consumer rebalance. This is mostly due to another stream with same group id joined,please check if there're different streaming application misconfigure to use same group id. Fundamentally different stream should use different group id
	
	3). Attempt to heart beat failed since the group is rebalancing, try to re-join group
	
	4). Offsets out of range with no configured reset policy for partitions
		spark-stream的executor中auto.offset.reset置为none,所以当groupid中记录的offset超出记录的上下边界，报此错误
		https://www.jianshu.com/p/40aee290f484
	
18. java.lang.OutOfMemoryError: unable to create new native thread
	spark程序执行过程中出现HDFS相关错误
	修改linux open files限制，设置 ulimit -n xxxx提升限制，ulimit -a查看
	
19. 安心云ES存储代码复制到知物云出现 NoAvaliable Nodes 错误
	ES库版本问题(zhiwu-5.5  anxinyun-6.5)
		<dependency>
            <groupId>org.elasticsearch.client</groupId>
            <artifactId>transport</artifactId>
            <version>6.2.4</version>
        </dependency>
	
20. flatMap && flatten
	// flatMap  TraversableLike.scala

	  def flatMap[B, That](f: A => GenTraversableOnce[B])(implicit bf: CanBuildFrom[Repr, B, That]): That = {
		def builder = bf(repr) // extracted to keep method size under 35 bytes, so that it can be JIT-inlined
		val b = builder
		for (x <- this) b ++= f(x).seq
		b.result
	  }
	  
	// flatten  GenericTraversableTemplate.scala

	  def flatten[B](implicit asTraversable: A => /*<:<!!!*/ GenTraversableOnce[B]): CC[B] = {
		val b = genericBuilder[B]
		for (xs <- sequential)
		  b ++= asTraversable(xs).seq
		b.result()
	  }

	两者功能上几乎没有区别
	通过 ++= 枚举元素进行添加，Map的相同键的元素会覆盖

21. ElasticSearch: [script] Too many dynamic script compilations within, max: [75/5m]
	修改ES配置 5.x max_compilations_per_minute   6.x script.max_compilations_rate
	动态修改:
	PUT /_cluster/settings
	{
		"transient" : {
			"script.max_compilations_rate" : "750/5m"
		}
	}
	
## APACHE SPARK -> FLINK
1. flink中使用joda.DateTime
	flink程序启动时提示 `class org.joda.time.DateTime does not contain a getter for field iMillis`
	  `Class class org.joda.time.DateTime cannot be used as a POJO type because not all fields are valid POJO fields`
	 因为DateTime中iMillis字段没有setter和getter，所以flink不能将其视为POJO类型（更多flink支持数据类型参见 https://ci.apache.org/projects/flink/flink-docs-stable/dev/types_serialization.html）
	 
	 如果使用了检查点（checkpoint）机制，需要设置jodatime的kyro序列化机制（跟spark-streaming是一样的处理）

2. flink启动过程出现NPE （NullPointException）
	因为代码里我将一个case class设置为null了，后将其改成Option[case class]的类型问题解决
	建议：如果数据结构中可能存在空（null）的情况，使用类型Option而不是直接用null赋值
	
3. java.lang.NoClassDefFoundError: org/slf4j/LoggerFactory
	在IDEA中程序可以执行，而打包的jar包无法运行
	你必须指定一种SLF4J的实现jar包在你的classpath里面，和接口jar包一样
	https://stackoverflow.com/questions/12926899/java-lang-noclassdeffounderror-org-slf4j-loggerfactory

	<!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 -->
	<dependency>
		<groupId>org.slf4j</groupId>
		<artifactId>slf4j-log4j12</artifactId>
		<version>1.7.25</version>
		<scope>test</scope>
	</dependency>
	
	或者查看是否在maven shade插件中过滤了log相关jar
	
